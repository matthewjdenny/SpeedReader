#' A function that implements a number of feature selection methods for finding top
#' words which distinguish between two classes.
#'
#' @param contingency_table A contingency table generated by the `contingency_table()` function.
#' @param rows_to_compare A numeric vector containing the indicies of the rows
#' in the contingency table we wish to compare against eachother. Defaults to
#' NULL, in which case all rows are compared against eachother.
#' @param alpha The Dirichlet hyperparameter to be used if method =
#' "informed_Dirichlet". Suggested value is the average number of terms that
#' appear in a document. If a small value is selected, then more (globally)
#' common terms may be selected as top words. Increasing the value will select
#' for less globally common words. Defaults to 1 (not usually a good choice for
#' most analyses).
#' @param method Defaults to "informed_Dirichlet", which implements the model
#'  described in section 3.5.1 of Monroe et al. "Fightin Words...". Can also be
#'  "TF-IDF", in which case canonical TF-IDF ranking is used. The user may also
#'  select "TF-IDF-log(tf)", in which case the TF term is logged following
#'  Manning and Schutze (1999, p.544), or "TF-IDF-augmented(tf)", in which case
#'  the TF term is augmented also following Manning and Schutze (1999, p.544).
#' @param maximum_top_words Controls the maximum number of top words returned in
#' each category. Defaults to 5000.
#' @param document_term_matrix The document term matrix used to construct the
#' contingency_table. Necessary if the user selects method = "TF-IDF". Defaults
#' to NULL.
#' @return A list object containing two dataframes (one for each comparison
#' category) with ranked top words. All words included in each dataset obtain
#' a z-score greater in magnitude than 1.96.
#' @export
feature_selection <- function(contingency_table,
                              rows_to_compare = NULL,
                              alpha = 1,
                              method = c("informed Dirichlet",
                                         "TF-IDF",
                                         "TF-IDF-log(tf)",
                                         "TF-IDF-augmented(tf)"),
                              maximum_top_words = 5000,
                              document_term_matrix = NULL){

    if (is.null(rows_to_compare)) {
        rows_to_compare <- 1:nrow(contingency_table)
    }

    if ((method == "TF-IDF" | method == "TF-IDF-log(tf)"| method ==
        "TF-IDF-augmented(tf)") & is.null(document_term_matrix)) {
        stop("You must provide a document_term_matrix if method == 'TF-IDF'")
    }

    # make sure we only use one method
    method <- method[1]

    # determine whether we are working with a sparse matrix
    is_sparse_matrix <- FALSE
    if(class(contingency_table) == "simple_triplet_matrix"){
        is_sparse_matrix <- TRUE
    }

    # get the vocabulary
    vocabulary <- colnames(contingency_table)

    cat("Generating column sums...\n")
    # get column sums
    category_list <- vector(mode = "list", length = length(rows_to_compare))
    if(is_sparse_matrix){
        colsums <- as.numeric(slam::col_sums(contingency_table))
        for(i in 1:length(rows_to_compare)) {
            category_list[[i]] <- as.numeric(slam::col_sums(
                contingency_table[rows_to_compare[i],]))
        }
        all_classes <- as.numeric(slam::col_sums(
            contingency_table[rows_to_compare,]))
    }else{
        colsums <- as.numeric(apply(contingency_table,2,sum))
        for(i in 1:length(rows_to_compare)) {
            category_list[[i]] <- as.numeric(
                contingency_table[rows_to_compare[i],])
        }
        all_classes <- as.numeric(contingency_table[rows_to_compare,])
    }

    to_return <- vector(mode = "list", length = length(rows_to_compare))
    #############################################
    ######## INFORMED DIRICHLET RANKING #########
    #############################################
    if (method == "informed Dirichlet") {
        # get the total number of tokens
        total_tokens <- sum(colsums)

        #calculate the prior contribution
        prior_contribution <- colsums * (alpha/total_tokens)

        cat("Calcualting log-odds ratios and variances...\n")

        for (i in 1:length(rows_to_compare)) {
            cat1 <- category_list[[i]]
            cat2 <- (all_classes - category_list[[i]])
            # now calculate the log-odds ratio for each token
            log_odds_ratio <- log(cat1 + prior_contribution) -
                log(sum(cat1) + alpha - cat1 - prior_contribution) -
                log(cat2 + prior_contribution) +
                log(sum(cat2) + alpha - cat2 - prior_contribution)

            # calculate the variance of the log-odds ratio using equation 19
            variance <- 1/(cat1 + prior_contribution) +
                1/(sum(cat1) + alpha - cat1 - prior_contribution) +
                1/(cat2 + prior_contribution) +
                1/(sum(cat2) + alpha - cat2 - prior_contribution)

            # subset everything to remove any NaNs (this comes in if we are using a
            # subset of documents where some words do not appear at all in any of them)
            vocab <- vocabulary
            remove <- which(is.nan(log_odds_ratio))
            if (length(remove) > 0) {
                log_odds_ratio <- log_odds_ratio[-remove]
                variance <- variance[-remove]
                vocab <- vocabulary[-remove]
                cat1 <- cat1[-remove]
                cat2 <- cat2[-remove]
            }


            # calculate z scores
            z_scores <- log_odds_ratio/sqrt(variance)

            #now get the significant words and rank them.
            cat("Finding top words in each category...\n\n")
            inds <- which(z_scores > 1.96)
            category_1_significant_words <- data.frame(
                term = vocab[inds],
                log_odds_ratio = log_odds_ratio[inds],
                variance = variance[inds],
                z_scores = z_scores[inds],
                count = cat1[inds],
                other_count = cat2[inds],
                stringsAsFactors = FALSE)
            ordering <- order(category_1_significant_words$z_scores,
                              decreasing = T)
            category_1_significant_words <- category_1_significant_words[ordering,]
            rownames(category_1_significant_words) <- category_1_significant_words$term

            #print out resutls
            cat("Top 20 terms for category:",
                rownames(contingency_table)[rows_to_compare[i]], "...\n")
            print(head(category_1_significant_words[,2:6],n = 20))

            # make sure we do not excede the max number of words
            if (nrow(category_1_significant_words) > maximum_top_words) {
                category_1_significant_words <- category_1_significant_words[1:maximum_top_words,]
            }

            to_return[[i]] <- category_1_significant_words
        }
    }

    #################################
    ######## TD-IDF RANKING #########
    #################################
    if (method == "TF-IDF" | method == "TF-IDF-log(tf)"| method ==
        "TF-IDF-augmented(tf)") {
        # calcualte document frequency (not logged)
        if (class(document_term_matrix) == "simple_triplet_matrix") {
            document_frequency <- rep(0, ncol(document_term_matrix))
            printseq <- round(seq(1,length(document_term_matrix$i),
                                  length.out = 11)[2:11],0)
            # fast C++ implementation
            document_frequency <- Sparse_Document_Frequencies(
                length(document_term_matrix$j),
                document_term_matrix$j,
                document_frequency,
                printseq,
                length(printseq))
            document_frequency <- as.numeric(document_frequency)
        } else {
            document_frequency <- calculate_document_frequency(
                document_term_matrix)
        }

        document_indices <- attr(contingency_table,"document_indices")

        num_docs <- nrow(document_term_matrix)
        for (i in 1:length(rows_to_compare)) {
            cat1 <- category_list[[i]]
            cat1 <- cat1/length(document_indices[[rows_to_compare[i]]])

            if (method == "TF-IDF-log(tf)") {
                cat1 <- 1 + log(cat1)
            }
            remove <- NULL
            if(method == "TF-IDF-augmented(tf)") {
                cat1 <- 0.5 + (0.5 * cat1)/max(cat1)
                temp <- which(cat1 == 0.5)
                if(length(temp) > 0){
                    remove <- temp
                }
            }

            # now calculate scores
            scores_1 <- cat1*log(num_docs/(1 + document_frequency))

            #remove NaN entries
            vocabulary1 <- vocabulary
            category_11 <- cat1
            doc_frequency1 <- document_frequency
            remove <- c(remove,which(is.nan(scores_1)))
            remove <- unique(remove)
            if (length(remove) > 0) {
                scores_1 <- scores_1[-remove]
                vocabulary1 <- vocabulary[-remove]
                category_11 <- cat1[-remove]
                doc_frequency1 <- document_frequency[-remove]
            }

            # make the dataframe to return
            category_1_significant_words <- data.frame(
                term = vocabulary1,
                tfidf = scores_1,
                count = category_11,
                idf = doc_frequency1,
                stringsAsFactors = FALSE)
            ordering <- order(category_1_significant_words$tfidf,
                              decreasing = T)
            category_1_significant_words <- category_1_significant_words[ordering,]
            rownames(category_1_significant_words) <- category_1_significant_words$term

            #print out resutls
            cat("Top 20 terms for category:",
                rownames(contingency_table)[rows_to_compare[i]], "...\n")
            print(head(category_1_significant_words[,2:4],n = 20))

            # make sure we do not excede the max number of words
            if (nrow(category_1_significant_words) > maximum_top_words) {
                category_1_significant_words <- category_1_significant_words[1:maximum_top_words,]
            }

            to_return[[i]] <- category_1_significant_words
        }
    }


    names(to_return) <- c(rownames(contingency_table)[rows_to_compare])

    return(to_return)
}
